<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Anqi Li</title>
  <meta name="author" content="Anqi Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>

<body>
  <div class="page-wrapper">
    <div class="container">
      <table class="main-table">
        <tbody>
          <tr>
            <td>
              <table class="header-table">
                <tbody>
                  <tr>
                    <td class="profile-text">
                      <h1>Anqi Li | 李安齐</h1>
                      <p>
                        I am a third-year undergraduate student at Yuanpei College, Peking University, majoring in Artificial Intelligence. </br>
                        I'm currently working in the <a href="https://pku-epic.github.io/">EPIC Lab</a> under the supervision of <a href="https://hughw19.github.io/">Prof. He Wang</a> and working closely with <a href="https://jzhzhang.github.io/">Jiazhao Zhang</a>. I focus on embodied AI, particularly vision-language-action models and their applications in robotic navigation.<br>
                        Outside of research, I enjoy playing basketball, performing on the trombone, and speedcubing.
                      </p>
                      <div class="social-links">
                        <a href="mailto:lianqi0417@stu.pku.edu.cn"><i class="fas fa-envelope"></i> Email</a>
                        <a href="https://github.com/andyhandsom6"><i class="fab fa-github"></i> GitHub</a>
                        <!-- Additional links can be added here -->
                      </div>
                    </td>
                    <td class="profile-img">
                      <div class="img-container">
                        <a href="images/anqi/Anqi.jpg">
                          <img src="images/anqi/Anqi.jpg" alt="Anqi Li">
                        </a>
                      </div>
                    </td>
                  </tr>
                </tbody>
              </table>
              
              <div class="section">
                <h2><i class="fas fa-flask"></i> Research</h2>
              </div>
              
              <table class="research-table">
                <tbody>
                  <tr>
                    <td class="research-img">
                      <div class="img-hover-container">
                        <div class="static-img">
                          <img src='images/trackvla/trackvla.png' alt="TrackVLA static">
                        </div>
                        <div class="animated-img">
                          <img src="images/trackvla/trackvla.gif" alt="TrackVLA animation">
                        </div>
                      </div>
                    </td>
                    <td class="research-details">
                      <a href="https://pku-epic.github.io/TrackVLA-web/">
                        <h3>TrackVLA: Embodied Visual Tracking in the Wild</h3>
                      </a>
                      <div class="authors">
                        Shaoan Wang*, Jiazhao Zhang*, Minghan Li, Jiahang Liu, 
                        <strong>Anqi Li</strong>, Kui Wu, Fangwei Zhong, Junzhi Yu, 
                        Zhizheng Zhang<sup>†</sup>, He Wang<sup>†</sup>
                      </div>
                      <div class="pub-info">
                        <em><strong>CoRL 2025</strong></em>
                      </div>
                      <div class="links">
                        <a href="https://arxiv.org/pdf/2505.23189"><i class="fas fa-file-pdf"></i> Paper</a>
                        <a href="https://github.com/wsakobe/TrackVLA"><i class="fas fa-code"></i> Code</a>
                        <a href="https://pku-epic.github.io/TrackVLA-web/"><i class="fas fa-link"></i> Project page</a>
                      </div>
                      <p>
                        TrackVLA is a vision-language-action model capable of simultaneous object recognition and visual tracking, trained on a dataset of 1.7 million samples. It demonstrates robust tracking, long-horizon tracking, and cross-domain generalization across diverse challenging environments.
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>

              <div class="section">
                <h2><i class="fas fa-briefcase"></i> Experience</h2>
              </div>
              
              <table class="experience-table">
                <tbody>
                  <tr>
                    <td class="logo-cell">
                      <div class="logo-container">
                        <img src="images/galbot.png" alt="Galbot">
                      </div>
                    </td>
                    <td class="exp-details">
                      <h3>Galbot</h3>
                      <div class="exp-meta">
                        <span>China</span>
                        <span>2025.02 - Present</span>
                      </div>
                      <p><strong>Research Intern</strong></p>
                      <p>Research Advisor: Prof. <a href="https://hughw19.github.io/">He Wang</a>, Dr. <a href="https://scholar.google.com/citations?user=X7M0I8kAAAAJ&hl=en">Zhizheng Zhang</a></p>
                    </td>
                  </tr>
                </tbody>
                <tbody>
                  <tr>
                    <td class="logo-cell">
                      <div class="logo-container">
                        <img src="images/peking_university.png" alt="Peking University">
                      </div>
                    </td>
                    <td class="exp-details">
                      <h3>Peking University</h3>
                      <div class="exp-meta">
                        <span>China</span>
                        <span>2023.09 - Present</span>
                      </div>
                      <p><strong>Undergraduate Student</strong></p>
                      <p>Research Advisor: Prof. <a href="https://hughw19.github.io/">He Wang</a></p>
                    </td>
                  </tr>
                </tbody>
              </table>
              
              <div class="footer">
                <p>
                  Template adapted from <a href="https://jonbarron.info/">Jon Barron</a>.
                  <br> Last updated: Aug. 2, 2025
                </p>
              </div>
            </td>
          </tr>
        </tbody>
      </table>
    </div>
  </div>
</body>
</html>